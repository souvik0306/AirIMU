"""Evaluate ROS inference outputs.

This script mirrors ``evaluation/evaluate_state.py`` but reads IMU
corrections from a pickle file produced by the ROS inference node.  The
pickle contains a list of chunks, each with ``correction_acc`` and
``correction_gyro`` arrays.  The script loads the corresponding EuRoC
sequence from disk, applies the corrections, and computes the same
metrics and plots as the original evaluation utility.
"""

import os
import sys
import argparse
import json
import pickle
from typing import Dict, List

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir)))

import numpy as np
import pypose as pp
import torch
import torch.utils.data as data

from pyhocon import ConfigFactory

from datasets import SeqDataset, SeqInfDataset, imu_seq_collate
from utils import integrate
from utils.visualize_state import (
    visualize_rotations,
    visualize_state_error,
    visualize_trajectory,
)


def _load_ros_pickle(path: str, device: str) -> Dict[str, torch.Tensor]:
    """Load ROS inference chunks and return tensors expected by ``SeqInfDataset``."""

    with open(path, "rb") as handle:
        chunks: List[Dict[str, np.ndarray]] = pickle.load(handle)

    if not isinstance(chunks, list):
        raise TypeError("ROS pickle must contain a list of chunk dictionaries")

    corr_acc = np.concatenate([c["correction_acc"] for c in chunks], axis=0)
    corr_gyro = np.concatenate([c["correction_gyro"] for c in chunks], axis=0)

    return {
        "correction_acc": torch.from_numpy(corr_acc).to(device).double().unsqueeze(0),
        "correction_gyro": torch.from_numpy(corr_gyro).to(device).double().unsqueeze(0),
    }


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--pickle",
        type=str,
        required=True,
        help="Path to net_output.pickle generated by the ROS node",
    )
    parser.add_argument(
        "--seq-name",
        type=str,
        default="seq0",
        help="Name of the sequence (matches config data_drive entry)",
    )
    parser.add_argument(
        "--seqlen",
        type=int,
        default=200,
        help="Length of integration sequence",
    )
    parser.add_argument(
        "--dataconf",
        type=str,
        default="configs/datasets/BaselineEuroc/Euroc_1000.conf",
        help="Dataset configuration file",
    )
    parser.add_argument(
        "--savedir",
        type=str,
        default="./result/loss_result",
        help="Directory to save plots and JSON",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cpu",
        help="Computation device",
    )
    parser.add_argument(
        "--usegtrot",
        action="store_true",
        help="Use ground-truth orientation for gravity compensation",
    )
    parser.add_argument(
        "--mask",
        action="store_true",
        help="Mask trajectory segments if dataset provides masks",
    )

    args = parser.parse_args()

    config = ConfigFactory.parse_file(args.dataconf)
    dataset_conf = config.inference

    # locate dataset configuration that contains the requested sequence
    seq_conf = None
    for conf in dataset_conf.data_list:
        if args.seq_name in conf.data_drive:
            seq_conf = conf
            break
    if seq_conf is None:
        raise ValueError(f"Sequence '{args.seq_name}' not found in dataset config")

    inference_state = _load_ros_pickle(args.pickle, args.device)

    os.makedirs(args.savedir, exist_ok=True)
    results = []

    # load raw dataset and integrators
    dataset = SeqDataset(
        seq_conf.data_root,
        args.seq_name,
        args.device,
        name=seq_conf.name,
        duration=args.seqlen,
        step_size=args.seqlen,
        drop_last=False,
        conf=dataset_conf,
    )
    loader = data.DataLoader(
        dataset=dataset,
        batch_size=1,
        collate_fn=imu_seq_collate,
        shuffle=False,
        drop_last=False,
    )

    init = dataset.get_init_value()
    gravity = dataset.get_gravity()

    integrator_outstate = pp.module.IMUPreintegrator(
        init["pos"], init["rot"], init["vel"], gravity=gravity, reset=False
    ).to(args.device).double()
    integrator_reset = pp.module.IMUPreintegrator(
        init["pos"], init["rot"], init["vel"], gravity=gravity, reset=True
    ).to(args.device).double()

    outstate = integrate(
        integrator_outstate,
        loader,
        init,
        device=args.device,
        gtinit=False,
        save_full_traj=True,
        use_gt_rot=args.usegtrot,
    )
    relative_outstate = integrate(
        integrator_reset,
        loader,
        init,
        device=args.device,
        gtinit=True,
        use_gt_rot=args.usegtrot,
    )

    # dataset with corrections applied
    dataset_inf = SeqInfDataset(
        seq_conf.data_root,
        args.seq_name,
        inference_state,
        device=args.device,
        name=seq_conf.name,
        duration=args.seqlen,
        step_size=args.seqlen,
        drop_last=False,
        conf=dataset_conf,
    )
    infloader = data.DataLoader(
        dataset=dataset_inf,
        batch_size=1,
        collate_fn=imu_seq_collate,
        shuffle=False,
        drop_last=True,
    )
    integrator_infstate = pp.module.IMUPreintegrator(
        init["pos"], init["rot"], init["vel"], gravity=gravity, reset=False
    ).to(args.device).double()
    infstate = integrate(
        integrator_infstate,
        infloader,
        init,
        device=args.device,
        gtinit=False,
        save_full_traj=True,
        use_gt_rot=args.usegtrot,
    )
    relative_infstate = integrate(
        integrator_reset,
        infloader,
        init,
        device=args.device,
        gtinit=True,
        use_gt_rot=args.usegtrot,
    )

    index_id = dataset.index_map[:, -1]
    mask = torch.ones(dataset.seqlen, dtype=torch.bool)
    select_mask = torch.ones_like(dataset.get_mask()[index_id], dtype=torch.bool)

    if args.mask:
        mask = dataset.get_mask()[: dataset.seqlen]
        select_mask = dataset.get_mask()[index_id]
        select_mask[-1] = False

    result_dic = {
        "name": args.seq_name,
        "use_gt_rot": args.usegtrot,
        "AOE(raw)": 180.0 / np.pi * outstate["rot_dist"][0, mask].mean().numpy(),
        "ATE(raw)": outstate["pos_dist"][0, mask].mean().item(),
        "AVE(raw)": outstate["vel_dist"][0, mask].mean().item(),
        "ROE(raw)": 180.0
        / np.pi
        * relative_outstate["rot_dist"][0, select_mask].mean().numpy(),
        "RTE(raw)": relative_outstate["pos_dist"][0, select_mask].mean().item(),
        "RVE(raw)": relative_outstate["vel_dist"][0, select_mask].mean().item(),
        "RP_RMSE(raw)": np.sqrt(
            (relative_outstate["pos_dist"][0, select_mask] ** 2).mean()
        ).numpy().item(),
        "RV_RMSE(raw)": np.sqrt(
            (relative_outstate["vel_dist"][0, select_mask] ** 2).mean()
        ).numpy().item(),
        "RO_RMSE(raw)": 180.0
        / np.pi
        * torch.sqrt(
            (relative_outstate["rot_dist"][0, select_mask] ** 2).mean()
        ).item(),
        "O_RMSE(raw)": 180.0
        / np.pi
        * torch.sqrt((outstate["rot_dist"][0, mask] ** 2).mean()).item(),
        "AOE(AirIMU)": 180.0
        / np.pi
        * infstate["rot_dist"][0, mask].mean().numpy(),
        "ATE(AirIMU)": infstate["pos_dist"][0, mask].mean().item(),
        "AVE(AirIMU)": infstate["vel_dist"][0, mask].mean().item(),
        "ROE(AirIMU)": 180.0
        / np.pi
        * relative_infstate["rot_dist"][0, select_mask].mean().numpy(),
        "RTE(AirIMU)": relative_infstate["pos_dist"][0, select_mask].mean().item(),
        "RVE(AirIMU)": relative_infstate["vel_dist"][0, select_mask].mean().item(),
        "RP_RMSE(AirIMU)": np.sqrt(
            (relative_infstate["pos_dist"][0, select_mask] ** 2).mean()
        ).item(),
        "RV_RMSE(AirIMU)": np.sqrt(
            (relative_infstate["vel_dist"][0, select_mask] ** 2).mean()
        ).item(),
        "RO_RMSE(AirIMU)": 180.0
        / np.pi
        * torch.sqrt(
            (relative_infstate["rot_dist"][0, select_mask] ** 2).mean()
        ).numpy(),
        "O_RMSE(AirIMU)": 180.0
        / np.pi
        * torch.sqrt((infstate["rot_dist"][0, mask] ** 2).mean()).numpy(),
    }

    results.append(result_dic)

    print("==============Integration==============")
    print("pos_err:", outstate["pos_dist"].mean())
    print("rot_err:", outstate["rot_dist"].mean())
    print("vel_err:", outstate["vel_dist"].mean())

    print("==============AirIMU==============")
    print("pos_err:", infstate["pos_dist"].mean())
    print("rot_err:", infstate["rot_dist"].mean())
    print("vel_err:", infstate["vel_dist"].mean())

    visualize_state_error(
        args.seq_name,
        outstate,
        infstate,
        save_folder=args.savedir,
        mask=mask,
        file_name="inte_error_compare.png",
    )
    visualize_state_error(
        args.seq_name,
        relative_outstate,
        relative_infstate,
        mask=select_mask,
        save_folder=args.savedir,
    )
    visualize_rotations(
        args.seq_name,
        outstate["orientations_gt"][0],
        outstate["orientations"][0],
        infstate["orientations"][0],
        save_folder=args.savedir,
    )
    visualize_trajectory(args.seq_name, args.savedir, outstate, infstate)

    with open(os.path.join(args.savedir, "loss_result.json"), "w") as f:
        json.dump(results, f, indent=4)


if __name__ == "__main__":
    main()

